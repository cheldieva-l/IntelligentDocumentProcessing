{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Введение"
   ],
   "metadata": {
    "id": "S-5ikg1xhmXW"
   },
   "id": "S-5ikg1xhmXW"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В предыдущих тетрадках мы прошли все этапы пайплайна по обработке документов - от подготовки данных для обучения моделей до написания метрик. Нам остается только собрать все кусочки в один единый сервис. \n",
    "\n",
    "В этой тетрадке будем немного оптимизировать инференс, объединять детекцию, распознавание и извлечение сущностей и считать end-to-end метрики. План примерно такой: \n",
    "\n",
    "1. Инференс детектора текста;\n",
    "2. Инференс распознавания текста; \n",
    "3. Инференс модели для линий; \n",
    "4. Объединение линий в параграфы; \n",
    "5. Объединение предыдущих четырех шагов в один метод по обработке изображения; \n",
    "6. Получить предсказание с помощью NER модели для распознанного текста\n",
    "7. Подготовить данные и расчитать метрики\n",
    "8. Собрать сервис на flask\n",
    "\n",
    "Также на каждом этапе будем визуализировать результаты, чтобы убедиться, что мы ничего нигде не забыли. Поехали! \n",
    "\n",
    "Следующие несколько ячеек будут общими для всех ноутбуков."
   ],
   "metadata": {
    "id": "B9s6nbf5iiX8"
   },
   "id": "B9s6nbf5iiX8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Эта ячейка настраивает отображение ipython widgets"
   ],
   "metadata": {
    "id": "sqWUmFLkCuHe"
   },
   "id": "sqWUmFLkCuHe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12638cf1"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%matplotlib inline"
   ],
   "id": "12638cf1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Подключаем Google Drive"
   ],
   "metadata": {
    "id": "BsgqZicPC9WP"
   },
   "id": "BsgqZicPC9WP"
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "nTZUKkVy2tx_"
   },
   "execution_count": null,
   "outputs": [],
   "id": "nTZUKkVy2tx_"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_JJiFkCPzkA"
   },
   "source": [
    "* Указываем путь к папке с кодом: "
   ],
   "id": "Q_JJiFkCPzkA"
  },
  {
   "cell_type": "code",
   "source": [
    "repo_folder = '/content/drive/MyDrive/DeepLearning2/'"
   ],
   "metadata": {
    "id": "MvTRdw0utomB"
   },
   "execution_count": null,
   "outputs": [],
   "id": "MvTRdw0utomB"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Устанавливаем зависимости"
   ],
   "metadata": {
    "id": "vy13l3D3DEhm"
   },
   "id": "vy13l3D3DEhm"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AxH5yiBDMYO"
   },
   "outputs": [],
   "source": [
    "reqs_path = repo_folder + 'IntelligentDocumentProcessing/requirements.txt '\n",
    "!pip3 install -r {reqs_path}"
   ],
   "id": "1AxH5yiBDMYO"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Подключаем WandB"
   ],
   "metadata": {
    "id": "THY5IHJFDYk-"
   },
   "id": "THY5IHJFDYk-"
  },
  {
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "wandb_key = open('/content/drive/MyDrive/ssh/wandbkey.txt').read().strip()\n",
    "wandb.login(key=wandb_key)"
   ],
   "metadata": {
    "id": "jtsEzC93Da0b"
   },
   "execution_count": null,
   "outputs": [],
   "id": "jtsEzC93Da0b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Подключаем утилиты для этого ноутбука"
   ],
   "metadata": {
    "id": "cJXnmTwXDgft"
   },
   "id": "cJXnmTwXDgft"
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "base_folder = repo_folder + 'IntelligentDocumentProcessing/Resources/e_Service_Deployment/'  # import utils\n",
    "sys.path.append(base_folder)\n",
    "sys.path.append(repo_folder + 'IntelligentDocumentProcessing/Resources/')  # from a_Text_Detection.utils import\n",
    "sys.path.append(repo_folder)  # from IntelligentDocumentProcessing.Resources.a_Text_Detection.utils import"
   ],
   "metadata": {
    "id": "3iq7I9ft4-o_"
   },
   "execution_count": null,
   "outputs": [],
   "id": "3iq7I9ft4-o_"
  },
  {
   "cell_type": "markdown",
   "id": "281c053a",
   "metadata": {
    "id": "281c053a"
   },
   "source": [
    "# 1: Перевод изображения в текст"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d3742",
   "metadata": {
    "id": "f46d3742"
   },
   "source": [
    "## 1.1: Вход в пайплайн: изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412202e",
   "metadata": {
    "id": "c412202e"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_fpath = base_folder+'ner_sample/821284f7-4c42-491e-b85d-9d37a2ce7a56.jpeg'\n",
    "\n",
    "image = cv2.imread(image_fpath)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb0e12",
   "metadata": {
    "id": "d7fb0e12"
   },
   "outputs": [],
   "source": [
    "from c_Layout_Analisys.utils import resize_aspect_ratio\n",
    "\n",
    "device = 'cpu'\n",
    "max_image_size = 2048\n",
    "\n",
    "image_resized, _, _ = resize_aspect_ratio(image, square_size=max_image_size, interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96782a24",
   "metadata": {
    "id": "96782a24"
   },
   "source": [
    "## 1.2: Детекция текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e002e5",
   "metadata": {
    "id": "b0e002e5"
   },
   "source": [
    "Сначала на изображении найдем все локации, где есть текст и границы текста.\n",
    "\n",
    "Для этого возьмем модель, которую мы обучили для этой цели, и применим ко входному изображению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30032ce",
   "metadata": {
    "id": "a30032ce"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model_fpath = '/content/drive/MyDrive/DeepLearning2/td.jit'\n",
    "text_detection_model = torch.jit.load(model_fpath, map_location=torch.device(device))\n",
    "text_detection_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3661c13",
   "metadata": {
    "id": "c3661c13"
   },
   "source": [
    "### Задача 1 (разминочная)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295be2e2",
   "metadata": {
    "id": "295be2e2"
   },
   "source": [
    "Метод для инференса детекции текста мы уже писали в первой тетрадке, поэтому необходимо просто вставить код из первой тетрадки сюда (только название должно быть `text_detection_inference`). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2a474",
   "metadata": {
    "id": "07f2a474"
   },
   "source": [
    "#### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2a834",
   "metadata": {
    "id": "69c2a834"
   },
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations import BasicTransform, Compose, OneOf\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from a_Text_Detection.utils import Postprocessor, DrawMore\n",
    "\n",
    "# КОД ДЛЯ СТУДЕНТА\n",
    "# сюда необходимо вставить код для инференса модели из тетрадки по детекции\n",
    "def text_detection_inference(\n",
    "    model: nn.Module, \n",
    "    image: np.ndarray, \n",
    "    transform: Union[BasicTransform, Compose, OneOf],\n",
    "    postprocessor: Postprocessor,\n",
    "    device: str = 'cpu',\n",
    ") -> List[np.ndarray]:\n",
    "    pass\n",
    "\n",
    "transform = ...\n",
    "postprocessor = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64fedc",
   "metadata": {
    "id": "5f64fedc"
   },
   "source": [
    "#### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348a8ac",
   "metadata": {
    "id": "4348a8ac"
   },
   "outputs": [],
   "source": [
    "pred_bboxes = text_detection_inference(text_detection_model, image_resized, \n",
    "                                       transform, postprocessor, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Тут и далее мы будем сохранять результаты разных этапов обработки документа в папку `results`, поэтому необходимо для начала ее создать. "
   ],
   "metadata": {
    "id": "AXsXvncik999"
   },
   "id": "AXsXvncik999"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.mkdir('results/')"
   ],
   "metadata": {
    "id": "aQsSN_iDkEd2"
   },
   "id": "aQsSN_iDkEd2",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a505044",
   "metadata": {
    "scrolled": true,
    "id": "9a505044"
   },
   "outputs": [],
   "source": [
    "countours_result = DrawMore.draw_contours(image_resized, pred_bboxes, thickness=2, color=(0, 0, 255))\n",
    "out_image_fpath = 'results/contours.png'\n",
    "cv2.imwrite(out_image_fpath, countours_result)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.imshow(countours_result.astype('int'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c6536",
   "metadata": {
    "id": "618c6536"
   },
   "source": [
    "## 1.3: Распознавание символов текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd4a31",
   "metadata": {
    "id": "a9bd4a31"
   },
   "source": [
    "На данный момент мы имеем изображене и прямоугольники (bounding box'ы), которые предсказала модель. Но на вход в OCR мы подаем вырезанные небольшие изображения, поэтому их необходимо достать из исходного изображения: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0c1a1",
   "metadata": {
    "id": "00b0c1a1"
   },
   "outputs": [],
   "source": [
    "from utils import prepare_crops\n",
    "\n",
    "crops = prepare_crops(image_resized, pred_bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5acb64",
   "metadata": {
    "id": "3d5acb64"
   },
   "source": [
    "### Задача 2 (тоже разминочная)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00499f",
   "metadata": {
    "id": "6b00499f"
   },
   "source": [
    "Вырезанные изображения подготовлены, но помимо предобработки есть еще постобработка. Как мы помним, ее в случае OCR выполняет токенизатор, который будет переводить предсказания модели в символы. В следующей ячейке мы предлагаем вставить его реализацию из тетрадки по OCR:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d581c",
   "metadata": {
    "id": "0a5d581c"
   },
   "source": [
    "#### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05649b",
   "metadata": {
    "id": "6e05649b"
   },
   "outputs": [],
   "source": [
    "# КОД ДЛЯ СТУДЕНТА\n",
    "# сюда необходимо вставить код токенайзера из тетрадки по распознаванию текста\n",
    "class TokenizerForCTC:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadf699e",
   "metadata": {
    "id": "aadf699e"
   },
   "source": [
    "#### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624f7f2",
   "metadata": {
    "id": "7624f7f2"
   },
   "outputs": [],
   "source": [
    "punct = \" !\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~«»№\"\n",
    "digit = \"0123456789\"\n",
    "cr = \"ЁАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяё\"\n",
    "latin = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "alphabet = punct + digit + cr + latin\n",
    "\n",
    "tokenizer = TokenizerForCTC(list(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "На всякий случае продублируем проверку токенизатора, чтобы убедиться, что мы скопировали то, что надо: "
   ],
   "metadata": {
    "id": "UQgB7PlEmkNt"
   },
   "id": "UQgB7PlEmkNt"
  },
  {
   "cell_type": "code",
   "source": [
    "correct_tensor = torch.tensor([132, 153, 149, 143, 152, 147, 164, 143, 156, 2]).unsqueeze(1)\n",
    "encoded = tokenizer.encode('Tokenizer!')\n",
    "assert len(encoded) == 2, 'Метод encode должен возвращать 2 элемента: тензор и длину последовательности.'\n",
    "assert torch.equal(encoded[0], correct_tensor), 'Строка \"Tokenizer!\" закодирована неправильно.'\n",
    "assert encoded[1] == 10, \"Метод encode вернул неправильную длину последовательности.\"\n",
    "\n",
    "decoded = tokenizer.decode([146, 146, 0, 143, 0, 150, 150, 0, 153])\n",
    "assert decoded == 'helo', \"Метод decode неправильно декодировал последовательность.\"\n",
    "\n",
    "decoded = tokenizer.decode([146, 146, 0, 143, 0, 150, 150, 0, 150, 153])\n",
    "assert decoded == 'hello', \"Метод decode неправильно декодировал последовательность с повторяющимися символами. \""
   ],
   "metadata": {
    "id": "A77Yz4gkmp3s"
   },
   "id": "A77Yz4gkmp3s",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее нам понадобится модель OCR, которую вы обучили: "
   ],
   "metadata": {
    "id": "-Tp9O2BHmtSX"
   },
   "id": "-Tp9O2BHmtSX"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9430352",
   "metadata": {
    "id": "c9430352"
   },
   "outputs": [],
   "source": [
    "ocr_model_fpath = '/content/drive/MyDrive/DeepLearning/ocr.jit'\n",
    "ocr_model = torch.jit.load(ocr_model_fpath, map_location=torch.device(device))\n",
    "ocr_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d9cb1",
   "metadata": {
    "id": "5a9d9cb1"
   },
   "source": [
    "### Задача 3: Батчевание инференса распознавания текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f82f1e",
   "metadata": {
    "id": "44f82f1e"
   },
   "source": [
    "У вас уже есть код для инференса модели для одного изображения, но делать инференс по одному изображению вычислительно невыгодно, поэтому теперь для оптимизации необходимо реализовать инференс с изменяемым размером батча. Итак, алгоритм:\n",
    "1. Разбить входящие изображения с помощью метода `batchings` (это функция-генератор, которая принимает на вход список объектов и размер батча, а возвращает с помощью `yield` батчи по очереди);\n",
    "3. Каждую картинку в батче преобразовать с помощью `resize_by_height`;\n",
    "4. Вычислить максимальную ширину изображения в батче; \n",
    "5. Добить все изображения в батче до одной ширины значениями `pad_value`. Можно использовать метод `torch.nn.functional.pad` или `cv2.copyMakeBorder`;\n",
    "6. Привести все изображения к тензорам и объединить в один тензор через `torch.stack`;\n",
    "7. Далее идет почти обычный инференс, только возвращать метод будет не строку, а список строк. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa161e1",
   "metadata": {
    "id": "0fa161e1"
   },
   "source": [
    "#### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545712c",
   "metadata": {
    "id": "1545712c"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import batchings\n",
    "from b_Optical_Character_Recognition.utils import resize_by_height\n",
    "\n",
    "# КОД ДЛЯ СТУДЕНТА\n",
    "def ocr_inference(\n",
    "    model: nn.Module, \n",
    "    image: np.ndarray, \n",
    "    transform: Union[BasicTransform, Compose, OneOf],\n",
    "    tokenizer: TokenizerForCTC, \n",
    "    device: str = 'cpu',\n",
    "    batch_size: int = 1,\n",
    "    target_height: int = 32,\n",
    "    pad_value: int = 0\n",
    ") -> List[str]:\n",
    "    pass\n",
    "\n",
    "transform = ...\n",
    "labels = ..."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "labels = ocr_inference(ocr_model, crops, transform, tokenizer, device, batch_size=8)"
   ],
   "metadata": {
    "id": "ZJSIkNDFoP5w"
   },
   "id": "ZJSIkNDFoP5w",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0eef1906",
   "metadata": {
    "id": "0eef1906"
   },
   "source": [
    "#### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a354def",
   "metadata": {
    "scrolled": true,
    "id": "5a354def"
   },
   "outputs": [],
   "source": [
    "from b_Optical_Character_Recognition.utils import draw_predictions\n",
    "\n",
    "out_image_fpath = 'results/ocr.png'\n",
    "_ = draw_predictions(\n",
    "    crops, \n",
    "    predicted_texts=labels, \n",
    "    path_to_save_image=out_image_fpath,\n",
    "    max_elements_to_draw=16\n",
    ")\n",
    "\n",
    "image = cv2.imread(out_image_fpath)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(15, 15), dpi=150)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed818cb",
   "metadata": {
    "id": "3ed818cb"
   },
   "outputs": [],
   "source": [
    "from c_Layout_Analisys.utils import Word\n",
    "\n",
    "words = [Word(bbox, label) for bbox, label in zip(pred_bboxes, labels) if len(label) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d13519",
   "metadata": {
    "id": "25d13519"
   },
   "source": [
    "## 1.4: Сборка текста в строки и параграфы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa473478",
   "metadata": {
    "id": "fa473478"
   },
   "source": [
    "Загружаем модель для предсказания строк, которая нам уже знакома. Напоминаем, что это модель с архитектурой DB (очень похожая на модель детекции текста), которая выдает нам линии, а линии необходимо собрать в параграфы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b735117",
   "metadata": {
    "id": "6b735117"
   },
   "outputs": [],
   "source": [
    "line_model_path = '/content/drive/MyDrive/DeepLearning/la.jit'\n",
    "line_model = torch.jit.load(line_model_path, map_location=torch.device(device))\n",
    "line_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c204031",
   "metadata": {
    "id": "4c204031"
   },
   "source": [
    "### Задача 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Возьмем код из тетрадки по layout analysis с инференсом модели по предсказанию линий: "
   ],
   "metadata": {
    "id": "MlnJxrEinaWL"
   },
   "id": "MlnJxrEinaWL"
  },
  {
   "cell_type": "markdown",
   "id": "8271cb31",
   "metadata": {
    "id": "8271cb31"
   },
   "source": [
    "#### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34799aad",
   "metadata": {
    "id": "34799aad"
   },
   "outputs": [],
   "source": [
    "from c_Layout_Analisys.utils import Line\n",
    "\n",
    "# необходимо вставить сюда инференс из тетрадки по layout\n",
    "# КОД ДЛЯ СТУДЕНТА\n",
    "def line_detector_inference(\n",
    "    model: nn.Module, \n",
    "    image: np.ndarray, \n",
    "    transform: Union[BasicTransform, Compose, OneOf],\n",
    "    postprocessor: Postprocessor,\n",
    "    device: str = 'cpu',\n",
    ") -> List[Line]:\n",
    "    pass\n",
    "\n",
    "transform = ...\n",
    "postprocessor = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d9d5b",
   "metadata": {
    "id": "b73d9d5b"
   },
   "source": [
    "#### Проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c16f5",
   "metadata": {
    "id": "145c16f5"
   },
   "source": [
    "Проверим детектирование строк текста: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f270e",
   "metadata": {
    "id": "2e1f270e"
   },
   "outputs": [],
   "source": [
    "lines = line_detector_inference(line_model, image_resized, transform, postprocessor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac5679",
   "metadata": {
    "scrolled": true,
    "id": "5cac5679"
   },
   "outputs": [],
   "source": [
    "from utils import group_words_by_lines_or_lines_by_paragraphs \n",
    "from c_Layout_Analisys.utils import sort_boxes\n",
    "\n",
    "# сгруппируем слова в линии по IOU\n",
    "h, w, _ = image_resized.shape\n",
    "lines = group_words_by_lines_or_lines_by_paragraphs(words, lines, w, h)\n",
    "lines = [line for line in lines if len(line.items) > 0]\n",
    "for line in lines:\n",
    "    line.items = sort_boxes(line.items, sorting_type = 'left2right')  # сортировка слева направо\n",
    "    line.label = ' '.join([word.label.strip() for word in line.items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cd613",
   "metadata": {
    "id": "ce2cd613"
   },
   "outputs": [],
   "source": [
    "lines_result = DrawMore.draw_contours(image_resized, [line.bbox for line in lines], thickness=2)\n",
    "out_image_fpath = 'results/lines.png'\n",
    "cv2.imwrite(out_image_fpath, lines_result)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.imshow(lines_result.astype('int'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a6acd",
   "metadata": {
    "id": "931a6acd"
   },
   "source": [
    "Загрузим объект класса `ParagraphFinder` и проверим сборку параграфов текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4cf72",
   "metadata": {
    "id": "3df4cf72"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import dill\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from c_Layout_Analisys.utils import sort_boxes_top2down_wrt_left2right_order, sort_boxes, fit_bbox, Paragraph\n",
    "\n",
    "\n",
    "with open('/content/drive/MyDrive/DeepLearning/paragraph_finder.pkl', 'rb') as r:\n",
    "    paragraph_finder = dill.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f840db",
   "metadata": {
    "id": "72f840db"
   },
   "outputs": [],
   "source": [
    "paragraphs = paragraph_finder.find_paragraphs(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab8450",
   "metadata": {
    "scrolled": true,
    "id": "d0ab8450"
   },
   "outputs": [],
   "source": [
    "for para in paragraphs:\n",
    "    para.label = ' '.join([line.label.strip() for line in para.items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361ea2f",
   "metadata": {
    "id": "5361ea2f"
   },
   "outputs": [],
   "source": [
    "para_result = DrawMore.draw_contours(image_resized, [para.bbox for para in paragraphs], thickness=2)\n",
    "out_image_fpath = 'results/paragraphs.png'\n",
    "cv2.imwrite(out_image_fpath, para_result)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.imshow(para_result.astype('int'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c743a",
   "metadata": {
    "id": "3c8c743a"
   },
   "source": [
    "## 1.5: Сборка end-to-end OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef5e8d",
   "metadata": {
    "id": "c6ef5e8d"
   },
   "source": [
    "Мы проверили, что каждый отдельный модуль приложения работает. Теперь сделаем функцию, которая на вход будет принимать документ, а на выходе будет выдавать текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c847d",
   "metadata": {
    "scrolled": false,
    "id": "143c847d"
   },
   "outputs": [],
   "source": [
    "from utils import visualize_e2e\n",
    "\n",
    "out_image_fpath = 'results/end2end.png'\n",
    "font_path = repo_folder + 'IntelligentDocumentProcessing/Resources/b_Optical_Character_Recognition/resources/fonts/times.ttf'\n",
    "_ = visualize_e2e(image_resized, paragraphs, font_path=font_path,\n",
    "                  fontsize=20, font_color=(0, 0, 0), thickness=2, show_words=True, \n",
    "                  show_lines=True, show_groups=True, path_to_save_image=out_image_fpath)\n",
    "\n",
    "image = cv2.imread(out_image_fpath)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(15, 12), dpi=150)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07fc2b5",
   "metadata": {
    "id": "c07fc2b5"
   },
   "source": [
    "### Задача 4. Полный пайплайн распознавания документа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e5813",
   "metadata": {
    "id": "d33e5813"
   },
   "source": [
    "У вас есть все готовые методы для распознавания - осталось только собрать их в один метод. Параметры метода, кроме `image` и `device`, вы определяете сами, а на выходе должен получиться список DTO типа `Paragraph`. Что должно быть внутри метода: \n",
    "\n",
    "1. Инференс модели детектора текста - метод `text_detection_inference` в помощь;\n",
    "1. Вызов метода `prepare_crops`, который вырезает из изображения прямоугольники с текстом; \n",
    "1. Инференс модели распознавания текста - метод `ocr_inference`;\n",
    "1. Инференс модели, которая находит линии - метод `line_detector_inference`;\n",
    "1. Объединение слов и линий с помощью метода `group_words_by_lines_or_lines_by_paragraphs`;\n",
    "1. Сортировка слов в линиях;\n",
    "1. Объединение линий в параграфы с помощью `paragraph_finder`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4093e723",
   "metadata": {
    "id": "4093e723"
   },
   "source": [
    "#### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116881e",
   "metadata": {
    "id": "0116881e"
   },
   "outputs": [],
   "source": [
    "# КОД ДЛЯ СТУДЕНТА\n",
    "def recognition_pipeline(\n",
    "    image: np.ndarray,\n",
    "    device: str,\n",
    "    **kwargs\n",
    ") -> List[Paragraph]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3f13a",
   "metadata": {
    "id": "d6b3f13a"
   },
   "source": [
    "#### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e179e",
   "metadata": {
    "scrolled": true,
    "id": "009e179e"
   },
   "outputs": [],
   "source": [
    "full_pipeline_paragraphs = recognition_pipeline(\n",
    "    image=image_resized, \n",
    "    device=device,\n",
    "    detection_model=text_detection_model,\n",
    "    detection_transform=transform,\n",
    "    detection_postprocessor=postprocessor,\n",
    "    line_model=line_model,\n",
    "    line_transform=transform,\n",
    "    line_postprocessor=postprocessor,\n",
    "    paragraph_model=paragraph_finder,\n",
    "    ocr_model=ocr_model,\n",
    "    ocr_transform=transform,\n",
    "    ocr_tokenizer=tokenizer,\n",
    "    ocr_batch_size=8\n",
    ")\n",
    "\n",
    "for para in full_pipeline_paragraphs:\n",
    "    for i, line in enumerate(para.items):\n",
    "        print(i, line.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "В следующей ячейке будут сравниваться параграфы, которые мы получили из метода `recognition_pipeline`, и те, которые мы получили, прогоняя модели по отдельности (в переменной `paragraphs`). "
   ],
   "metadata": {
    "id": "W-Nl6jQFKPkf"
   },
   "id": "W-Nl6jQFKPkf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c537c0",
   "metadata": {
    "id": "16c537c0"
   },
   "outputs": [],
   "source": [
    "para_msg = 'Количество параграфов после Е2Е не совпадает с количеством параграфов в paragraphs.'\n",
    "assert len(paragraphs) == len(full_pipeline_paragraphs), para_msg\n",
    "for para, fp_para in zip(paragraphs, full_pipeline_paragraphs):\n",
    "    label_msg = 'Текст каждого параграфа должен совпадать.'\n",
    "    assert para.label == fp_para.label, label_msg\n",
    "    bbox_msg = 'Bounding box каждого параграфа должен совпадать.'\n",
    "    assert np.array_equal(para.bbox, fp_para.bbox), bbox_msg\n",
    "    len_msg = 'Количество линий в каждом параграфе должно совпадать.'\n",
    "    assert len(para.items) == len(fp_para.items), len_msg\n",
    "    for line, fp_line in zip(para.items, fp_para.items):\n",
    "        label_msg = 'Текст каждой линии должен совпадать.'\n",
    "        assert line.label == fp_line.label, label_msg\n",
    "        bbox_msg = 'Bounding box каждой линии должен совпадать.'\n",
    "        assert np.array_equal(line.bbox, fp_line.bbox), bbox_msg\n",
    "        for word, fp_word in zip(line.items, fp_line.items):\n",
    "            label_msg = 'Текст каждого слова должен совпадать.'\n",
    "            assert word.label == fp_word.label, label_msg\n",
    "            bbox_msg = 'Bounding box каждого слова должен совпадать.'\n",
    "            assert np.array_equal(word.bbox, fp_word.bbox), bbox_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b760fc",
   "metadata": {
    "id": "57b760fc"
   },
   "source": [
    "### Задача 5. OCR на строках"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3319ad2",
   "metadata": {
    "id": "c3319ad2"
   },
   "source": [
    "Вы обучали OCR не просто на отдельных словах или парах слов, а на целых строках до 10-11 слов. Давайте теперь посмотрим, как эта модель себя поведет, если использовать ее на целых строках.\n",
    "\n",
    "Вам необходимо написать метод, который будет аналогичным методу `recognition_pipeline`, но только OCR будет применяться к задетектированным строкам. \n",
    "\n",
    "Также параметры данного метода вы выбираете самостоятельно (кроме `image` и `device`). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2027a8be",
   "metadata": {
    "id": "2027a8be"
   },
   "source": [
    "#### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8006ebd",
   "metadata": {
    "scrolled": true,
    "id": "e8006ebd"
   },
   "outputs": [],
   "source": [
    "# КОД ДЛЯ СТУДЕНТА\n",
    "def line_recognition_pipeline(\n",
    "    image: np.ndarray,\n",
    "    device: str,\n",
    "    **kwargs\n",
    ") -> List[Paragraph]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96605f0",
   "metadata": {
    "id": "b96605f0"
   },
   "source": [
    "#### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd81678",
   "metadata": {
    "scrolled": true,
    "id": "0cd81678"
   },
   "outputs": [],
   "source": [
    "line_pipeline_paragraphs = line_recognition_pipeline(\n",
    "    image=image_resized,\n",
    "    line_model=line_model,\n",
    "    line_transform=transform,\n",
    "    line_postprocessor=postprocessor,\n",
    "    paragraph_model=paragraph_finder,\n",
    "    ocr_model=ocr_model,\n",
    "    ocr_transform=transform,\n",
    "    ocr_tokenizer=tokenizer,\n",
    "    ocr_batch_size=8,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "for para in line_pipeline_paragraphs:\n",
    "    for i, line in enumerate(para.items):\n",
    "        print(i, line.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca31df",
   "metadata": {
    "id": "feca31df"
   },
   "source": [
    "## 1.6. Применение модели NER для полученного текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f2fa4",
   "metadata": {
    "id": "383f2fa4"
   },
   "source": [
    "Теперь наша задача запустить полный пайплайн, где на входе мы отправляем картинку, а на выходе имеет сущности с их координатами.\n",
    "\n",
    "Поэтому выделим два основных компнонета: \n",
    "\n",
    "* `OCR Pipeline`\n",
    "* `NER Model`\n",
    "\n",
    "\n",
    "C `OCR` нам теперь все понятно, соберем только все вместе и получим текст с которым будем работать в `NER` на примере одной картинки. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8153811",
   "metadata": {
    "id": "e8153811"
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "max_image_size = 2048\n",
    "\n",
    "image_fpath = './team_idp/ocr_service/ner_sample/821284f7-4c42-491e-b85d-9d37a2ce7a56.jpeg'\n",
    "\n",
    "image = cv2.imread(image_fpath)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image_resized, _, _ = resize_aspect_ratio(image, square_size=max_image_size, interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ac978",
   "metadata": {
    "id": "713ac978"
   },
   "outputs": [],
   "source": [
    "line_pipeline_paragraphs = line_recognition_pipeline(\n",
    "    image=image_resized,\n",
    "    line_model=line_model,\n",
    "    line_transform=transform,\n",
    "    line_postprocessor=postprocessor,\n",
    "    paragraph_model=paragraph_finder,\n",
    "    ocr_model=ocr_model,\n",
    "    ocr_transform=transform,\n",
    "    ocr_tokenizer=tokenizer,\n",
    "    ocr_batch_size=8,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "rec_text = \" \".join([line.label for para in line_pipeline_paragraphs for i, line in enumerate(para.items)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdac1f7",
   "metadata": {
    "id": "8cdac1f7"
   },
   "source": [
    "#### Визуализируем исходный документ и заодно посмотрим на текст из OCR Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21cad9",
   "metadata": {
    "id": "bf21cad9"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(image_fpath)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print()\n",
    "print(\"Recognized text: \")\n",
    "print()\n",
    "print(rec_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как и говорилось раньнее к этому занятию у вас должна быть обучена `NER` модель на основе датасета `RuRed`. Загружаем лучший ваш чекпоинт, сконвертированный в `jit`. \n"
   ],
   "metadata": {
    "id": "oTWm1KPW3APm"
   },
   "id": "oTWm1KPW3APm"
  },
  {
   "cell_type": "code",
   "source": [
    "rec_text = \"\"\"\n",
    "  Владимиру Комлеву вручили первую карту игрока\n",
    "  В НХЛ на базе «Мира» .\n",
    "  22 декабря, в день 70летия российского хоккея, был праздник.\n",
    "  В генеральный директор АО «КПК» Владимир Комлев стал чеспионом.\n",
    "  В первым держателем карты игрока Ночной Хоккейнойв Лиги (НХЛ), выпущенной на базе платежной системы\n",
    "  «Мир», Карту Владимиру Комлеву вручили президент Обанка «Югра» Алексей Нефедов и президент Ночной. \n",
    "  \"\"\""
   ],
   "metadata": {
    "id": "f0xOaatD5cdS"
   },
   "id": "f0xOaatD5cdS",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b4daa",
   "metadata": {
    "id": "e33b4daa"
   },
   "outputs": [],
   "source": [
    "model = torch.jit.load(\"./drive/MyDrive/weights/ner_rured.jit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520cd1e",
   "metadata": {
    "id": "f520cd1e"
   },
   "outputs": [],
   "source": [
    "from ner_model import inference_ner_model\n",
    "from ipymarkup import show_span_line_markup\n",
    "\n",
    "# Готовим примеры для подачи в датасет, оставляем формат, который был использован при обучении, но без сущностей\n",
    "samples = [((0, len(rec_text), rec_text),[])]\n",
    "\n",
    "result = inference_ner_model(samples, model, \"cpu\", batch_size = 4, num_workers = 4)\n",
    "\n",
    "for sample_predictions in result:\n",
    "    show_span_line_markup(*sample_predictions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Итого:\n",
    "  - Мы собрали рабочий пайплайн, котрый умеет превращать картинку в текст и извлекать из текста некоторый набор сущностей.\n",
    "\n",
    "  - Мы МОЛОДЦЫ!\n",
    "\n",
    "  - Однако есть еще работа, которую мы должны выполнить. О ней речь пойдет в следующей главе этой тетрадки."
   ],
   "metadata": {
    "id": "n78PPsJq5qF8"
   },
   "id": "n78PPsJq5qF8"
  },
  {
   "cell_type": "markdown",
   "id": "9e5f6831",
   "metadata": {
    "id": "9e5f6831"
   },
   "source": [
    "# 2. Тестирование итогового пайплайна структурирования информации\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a42248",
   "metadata": {
    "id": "53a42248"
   },
   "source": [
    "##  2.1. Подготовка данных для тестирования\n",
    "И снова нам нужно готовить данные, а именно сопоставить:\n",
    "- С точки зрения распознавания\n",
    "  - Изображение\n",
    "  - Предсказанный текстовый слой для изображения\n",
    "- С точки зрения извлечения:\n",
    "  - Исходный текст новости\n",
    "  - Разметку для исходного текста \n",
    "  - Предсказания `NER` модели\n",
    "\n",
    "Все это нам нужно для того, что замерить качество структурирования информации полным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f3cae",
   "metadata": {
    "id": "9a0f3cae"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def map_images_and_annotation(annotation_path: str, images_path: str):\n",
    "    \n",
    "    annotation_path_mask = os.path.join(annotation_path, \"*.ann\")\n",
    "    annot_files = glob(annotation_path_mask)\n",
    "    mapping = []\n",
    "\n",
    "    for ann_file in annot_files:\n",
    "        _, name = os.path.split(ann_file)\n",
    "        id_file = name.split(\"_\")[0]\n",
    "        text_file = f\"{ann_file[:-4]}.txt\"\n",
    "        image_paths = glob(os.path.join(images_path, f\"{name[:-4]}*.jpg\"))          \n",
    "        mapping.append((ann_file, text_file, image_paths))\n",
    "        \n",
    "    return mapping\n",
    "            \n",
    "            \n",
    "mapping_markup_image = map_images_and_annotation(\n",
    "    \"team_idp/ner/RuRED-splitted/test\", \n",
    "    \"../one_column/test/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Небольшое пояснение: маппинг возвращает список изобращений по той причине, что часть новостей весьма длинные и поэтому были размещены на нескольких страницах."
   ],
   "metadata": {
    "id": "bIw7KJ9V8TEX"
   },
   "id": "bIw7KJ9V8TEX"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f32cb6",
   "metadata": {
    "id": "19f32cb6"
   },
   "outputs": [],
   "source": [
    "mapping_markup_image[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3621d2",
   "metadata": {
    "id": "1b3621d2"
   },
   "source": [
    "Считаем разметку из пары файлов:  \n",
    "- `document1.ann`\n",
    "- `doсument1.txt`\n",
    "\n",
    "Этот метод уже был имплементирован у нас в тетрадке по `NER`.  Я перенес его в утилиты, так что воспользуемся готовым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfad57",
   "metadata": {
    "id": "1bdfad57"
   },
   "outputs": [],
   "source": [
    "from ner_model import read_annotation_pair\n",
    "\n",
    "read_annotation_pair(*mapping_markup_image[0][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc0fe8",
   "metadata": {
    "id": "29fc0fe8"
   },
   "source": [
    "### Задача 6: Подокументная обработка полным пайплайном\n",
    "\n",
    "Сейчас у нас есть одна нестыковка: пайплайн `OCR` наботает на уровне страницы, модель `NER` на уровне предложений, пора это все привести к общему знаменателю, а именно - **к документу**.\n",
    "\n",
    "Для этого нам потребуется:\n",
    "- прогонять все изображения одного через `OCR` (это у нас практически готово, не хватает цикла)\n",
    "- объединять распознынный текст с разных изображений (это легко!)\n",
    "- сегментировать текст на предложения для подачи в `NER` (это я сделал за вас)\n",
    "- прогонять примеры через модель (тут мы уже постарались, так что просто импортируем)\n",
    "- объединять сущности по предложениям в сущности по документам (здесь немного покодим)\n",
    "\n",
    "Так что вперед!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ba51b",
   "metadata": {
    "id": "216ba51b"
   },
   "source": [
    "Для начала посмотрим как работает сегментация и что она нам вернет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa7285",
   "metadata": {
    "id": "1dfa7285"
   },
   "outputs": [],
   "source": [
    "from ner_model import sentence_split\n",
    "\n",
    "text = \"СЕйчасс Будем проверять тесст после расп0завания на т0 как он делитьСя на предло)|(ения. В лучшем случае это будет так .\"\n",
    "\n",
    "expected_result = [\n",
    "    (\n",
    "        (0, 89, 'СЕйчасс Будем проверять тесст после расп0завания на т0 как он делитьСя на предло)|(ения.'), # предложения и его координаты в документе\n",
    "        [] # список в котором должны находиться сущности, если бы тренировали модель, на инференсе это просто легаси, чтобы не переделывать CustomDataset\n",
    "     ),\n",
    "    (\n",
    "        (89, 121, 'В лучшем случае это будет так .'),  # предложения и его координаты в документе\n",
    "        [] # легаси\n",
    "     )\n",
    "]\n",
    "\n",
    "current_result = sentence_split(text)\n",
    "\n",
    "assert expected_result == current_result, \"Не совпадает с ожидаемым результатом, нужно проверить выходной формат данных\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945b1c2",
   "metadata": {
    "id": "5945b1c2"
   },
   "source": [
    "#### Подзадача 1: Объединение предсказаний `NER` модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361ee53",
   "metadata": {
    "id": "3361ee53"
   },
   "source": [
    "Сейчас сущности имеют координаты в символах относительно каждого предложения, а нужно иметь набор сущностей на целый документ. Предложения пусть объединяются через пробел."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c64a22",
   "metadata": {
    "id": "49c64a22"
   },
   "source": [
    "##### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d9161c",
   "metadata": {
    "id": "a3d9161c"
   },
   "outputs": [],
   "source": [
    "# КОД ДЛЯ СТУДЕНТА\n",
    "\n",
    "def merge_predictions(document_predictions: List[Tuple[str, list]]) -> Tuple[str, list]:\n",
    "    markup = []\n",
    "    text = \"\"\n",
    "    # \n",
    "    # Дополнение по коду\n",
    "    # \n",
    "    return text, markup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08218fd",
   "metadata": {
    "id": "f08218fd"
   },
   "source": [
    "##### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b7e75",
   "metadata": {
    "id": "dd1b7e75"
   },
   "outputs": [],
   "source": [
    "## Проверка имплементации\n",
    " \n",
    "samples = [(\"Есть два предложения: со странными сущностями.\", [(5, 9, \"Числительное\")]), (\"Нужно проверить что объединение корректно\", [(0, 6 , \"Глагол\")])]\n",
    "expected_result = (\"Есть два предложения: со странными сущностями. Нужно проверить что объединение корректно\", [(5, 9, \"Числительное\"), (47, 53 , \"Глагол\")])\n",
    "\n",
    "current_result = merge_predictions(samples)\n",
    "\n",
    "assert current_result == expected_result, \"Скорее всего не совпали координаты сущностей после смещения\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57bb05c",
   "metadata": {
    "id": "c57bb05c"
   },
   "source": [
    "#### Подзадача 2: Прогон пайплайна \n",
    "\n",
    "Как и говорилось выше нам нужно собрать в одном месте 4 абстракции, для дальнейшей оценки качества сервиса (сами изображения нам уже не пригодятся):\n",
    "- Исходный текст новости (есть)\n",
    "- Предсказанный текстовый слой для изображения (запустим `OCR`)\n",
    "- Разметку для исходного текста (есть)\n",
    "- Предсказания модели извлечения (запустим `NER`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9d381",
   "metadata": {
    "id": "ebf9d381"
   },
   "source": [
    "##### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87d936",
   "metadata": {
    "id": "6b87d936"
   },
   "outputs": [],
   "source": [
    "# КОД ДЛЯ СТУДЕНТА\n",
    "information_per_document = [\n",
    "##  ( исходный текст, исходная раметка, текст после распознавания, предсказанные сущности )  \n",
    "]\n",
    "\n",
    "for ann_file, text_file, image_fpaths in mapping_markup_image:\n",
    "    \n",
    "    ## заводим цикл на список путей до изображения \n",
    "    \n",
    "        ## читаем изображение в память\n",
    "\n",
    "        ## меняем каналы\n",
    "\n",
    "        ## ресайзим \n",
    "\n",
    "        ## вызов пайплайна распознавания для каждого изображения\n",
    "        \n",
    "        ## объединияем все строки\n",
    "    \n",
    "    ## получение полнотекста для документа\n",
    "    \n",
    "    ## сегментация и форматирование примеров для подачи в модель извлечения \n",
    "    \n",
    "    ## инференс NER модели\n",
    "    \n",
    "    ## объединение выхода из модели извлечения\n",
    "    \n",
    "    ## чтение разметки и исходных текстов\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2dc47c",
   "metadata": {
    "id": "7e2dc47c"
   },
   "source": [
    "##### Проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3bb6a9",
   "metadata": {
    "id": "7d3bb6a9"
   },
   "source": [
    " Так как для инференса вы будете использовать модели, которые обучали самостоятельно, данное задание можно проверить только формально, по структуре данных. Поэтому возьмем один документ и проверим какие типы лежат на каждой из позиций тупла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246a524",
   "metadata": {
    "id": "8246a524"
   },
   "outputs": [],
   "source": [
    "first_sample = information_per_document[0]\n",
    "assert (len(first_sample) == 4) and \\             # должно быть 4 абстракции\n",
    "        isinstance(first_sample[0], str) and \\    # Исходный текст новости \n",
    "        isinstance(first_sample[2], str) and \\    # Предсказанный текстовый слой для изображения\n",
    "        isinstance(first_sample[1], list) and \\   # Разметк для исходного текста \n",
    "        isinstance(first_sample[3], list), \\      # Предсказания модели извлечения (запустим `NER`)\n",
    "        \"Структура данных не соответствует ожидаемой\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013f57a",
   "metadata": {
    "id": "a013f57a"
   },
   "outputs": [],
   "source": [
    "information_per_document[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ccb2e",
   "metadata": {
    "id": "ec5ccb2e"
   },
   "source": [
    "## 2.2. Замер метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c9be9",
   "metadata": {
    "id": "462c9be9"
   },
   "source": [
    "Будем реализовытать **жесткую** и единственно доступную метрику оценки качества работы сервиса: сверим сколько сущностей было в разметке и сколько сущностей предсказал наш набор моделей. Корректным ответом будет являться тот спан сущности, текст в котором частично/полностью совпадает с ground truth, кроме того он должен иметь аналогичный тип сущности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6629973",
   "metadata": {
    "id": "b6629973"
   },
   "source": [
    "### Задача 7: Оценка точности на тестовом наборе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d1d2c1",
   "metadata": {
    "id": "83d1d2c1"
   },
   "source": [
    "#### Подзадача 0: Метод для очистки и исправления текстов сущностей (в общем виде)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db233c5",
   "metadata": {
    "id": "7db233c5"
   },
   "source": [
    "Перед тем как сравнивать тексты сущностей, давайте попробуем их немного почистить, то есть подкорректровать. Ясно, что некорректный порядок токенов мы поправить не сможем, а вот регистр или частотную замену (путаницу) НУЛЯ и заглавной буквы O мы можем поправить. Имлементируйте метод text_precessing согласно ошибкам, которые вы видите в коде для проверки.\n",
    "\n",
    "**HINT**: а еще можете воспользоваться знанием того, как ошибается ваш OCR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe689f",
   "metadata": {
    "id": "2fbe689f"
   },
   "source": [
    "##### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97a3ae",
   "metadata": {
    "id": "1d97a3ae"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# КОД ДЛЯ СТУДЕНТА\n",
    "def text_precessing(text: str) -> str:\n",
    "    # \n",
    "    # Дополнение по коду\n",
    "    # \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4654088",
   "metadata": {
    "id": "c4654088"
   },
   "source": [
    "##### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b0a2d",
   "metadata": {
    "id": "2a6b0a2d"
   },
   "outputs": [],
   "source": [
    "## Проверка имплементации\n",
    "recognized_text = \"0дно дел0 простo ПРИВ0ДИТЬ все к НИжнему РЕГИСТРУ, с0всем другое - провести грамотный анализ ошибок модели ocr\"\n",
    "\n",
    "expected_result = \"одно дело простo приводить все к нижнему регистру, совсем другое - провести грамотный анализ ошибок модели ocr\"\n",
    "\n",
    "processed_text = text_precessing(recognized_text)\n",
    "\n",
    "assert expected_result == processed_text, \"Кажется нужно еще подумать на постобработкой\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2450b46",
   "metadata": {
    "id": "a2450b46"
   },
   "outputs": [],
   "source": [
    "def get_ents_texts(text: str, markup: list):\n",
    "    \"\"\"\n",
    "    Скипаем из разметки и предсказаний координаты и получаем список кортежей (тип сущности, текст сущности)\n",
    "    \"\"\"\n",
    "    return [(t, text_precessing(text[s:e])) for i, (s, e, t) in enumerate(markup)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c9e66",
   "metadata": {
    "id": "451c9e66"
   },
   "source": [
    "#### Подзадача 1: Метод оценки точности для одного документа\n",
    "\n",
    "Для дальнейшей агрегации результатов будем возвращать количество \"попаданий\" и количество сущностей из исходников разметки.\n",
    "\n",
    "Что имплементируем? Метод `accuracy_per_doc`, который позвовляет узнать насколько точно мы струтурировали информацию в рамках одного документа. Для этого реализуем:\n",
    "- получение текстов сущностей из разметки\n",
    "- получение текстов сущностей из предсказаний модели\n",
    "- сравнение текстов сущностей - полный перебор\n",
    "  - сущность считается корректно предсказанной если дистанция Левенштейна меньше или равна заданному параметру (при нахождении пары сущности удаляются из обоих списков)\n",
    "  - в противном случае не считаем сущность корректно предсказанной и не учитываем ее\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba047a",
   "metadata": {
    "id": "eeba047a"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f65be9a8",
   "metadata": {
    "id": "f65be9a8"
   },
   "source": [
    "##### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e46a01",
   "metadata": {
    "id": "c9e46a01"
   },
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "# КОД ДЛЯ СТУДЕНТА\n",
    "def accuracy_per_doc(\n",
    "    origin_text: str, markup: list, rec_text: str, predictions: list, lev_dist: int = 1\n",
    "):\n",
    "    gold_ents = get_ents_texts(origin_text, markup) # тексты сущностей из разметки\n",
    "    predict_ents = get_ents_texts(rec_text, predictions) # тексты предсказанных сущностей \n",
    "    same_ent = 0 # счетчик для корректных сущностей\n",
    "    # \n",
    "    # Дополнение по коду\n",
    "    # \n",
    "    return same_ent, len(gold_ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cffdd5a",
   "metadata": {
    "id": "1cffdd5a"
   },
   "source": [
    "##### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b88842",
   "metadata": {
    "id": "15b88842"
   },
   "outputs": [],
   "source": [
    "## Проверка имплементации\n",
    "\n",
    "gold_text = 'Проверка двух сущностей'\n",
    "gold_markup = [(0, 8, \"Test type 0\"), (9, 13, \"Test type 1\")]\n",
    "rec_text = 'Проветка двух сущностей'\n",
    "predict_markup = [(0, 8, \"Test type 0\"), (9, 13, \"Test type 1\")]\n",
    "\n",
    "TP, n_ents = accuracy_per_doc(gold_text, gold_markup, rec_text, predict_markup, lev_dist = 0)\n",
    "expected_result = (1, 2)\n",
    "assert (TP, n_ents) == expected_result, \"Accuracy is not correct\"\n",
    "\n",
    "TP, n_ents = accuracy_per_doc(gold_text, gold_markup, rec_text, predict_markup, lev_dist = 1)\n",
    "expected_result = (2, 2)\n",
    "assert (TP, n_ents) == expected_result, \"Accuracy is not correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58c511",
   "metadata": {
    "id": "1b58c511"
   },
   "source": [
    "### 2.2.1. Оценка моделей на тестовом датасете\n",
    "\n",
    "Осталось пропустить информацию из всех документов через нашу метрику и узнать сколько же правильных ответов мы дали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f130abc",
   "metadata": {
    "id": "5f130abc"
   },
   "outputs": [],
   "source": [
    "def dataset_accuracy(information_per_document: dict, lev_dist: int ):\n",
    "    match, all_ents = 0, 0\n",
    "    for sample_info in information_per_document:\n",
    "        match_doc, n_gold_ents = accuracy_per_doc(*sample_info, lev_dist)\n",
    "        match += match_doc\n",
    "        all_ents += n_gold_ents\n",
    "    print(f\"Accuracy: {round(match / all_ents * 100, 2)} with Lev distance: {lev_dist}\")\n",
    "    return match, all_ents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8b46e",
   "metadata": {
    "id": "b6e8b46e"
   },
   "outputs": [],
   "source": [
    "_ = dataset_accuracy(information_per_document, 0)\n",
    "print()\n",
    "_ = dataset_accuracy(information_per_document, 1)\n",
    "print()\n",
    "_ = dataset_accuracy(information_per_document, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59521042",
   "metadata": {
    "id": "59521042"
   },
   "source": [
    "# 3. Flask App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b90b6",
   "metadata": {
    "id": "d42b90b6"
   },
   "source": [
    "**Flask** - это веб-фреймворк, написанный на языке **Python**, предназначенный для создания веб-приложений. Он обеспечивает гибкость и имеет низкий порог вхождения, кроме того на нем написана уже не одна тысяча веб-сервисов и поэтмоу в сети найдется ответ на любой ваш вопрос. **Flask** — это расширяемая система, которая не обязывает использовать конкретную структуру директорий и не требует сложного шаблонного кода перед началом использования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6b6fb",
   "metadata": {
    "id": "c8e6b6fb"
   },
   "source": [
    "### Задача 8: \"Создание приложения на движке Flask\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a617dbef",
   "metadata": {
    "id": "a617dbef"
   },
   "source": [
    "####  Подзадача 0: \"Сборка класса Pipeline с основным методом predict\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eef2bd",
   "metadata": {
    "id": "a7eef2bd"
   },
   "source": [
    "Краткая постановка задачи:\n",
    "* На вход принимает считанный в память объект изображения для распознавания и извлечения\n",
    "* На выходе набор сущностей по типам с их текстами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb25af7",
   "metadata": {
    "id": "3cb25af7"
   },
   "source": [
    "##### Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3b7de",
   "metadata": {
    "id": "87d3b7de"
   },
   "outputs": [],
   "source": [
    "# КОД ДЛЯ СТУДЕНТА\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Здесь нужно проинициализировать все модели, с помощью которых мы будем\n",
    "        извлекать информацию и распознавать документы.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, image) -> dict:\n",
    "        \"\"\"\n",
    "        Изображение уже в памяти. Ресайзим, детектируем, распознаем, собираем в единый текст.\n",
    "        Сегментируем на предложения, извлекаем, объединяем и форматирем в словарь.\n",
    "        Return:  {\n",
    "            \"text\" : \"Успешные результаты распознавания текста\"\n",
    "            \"entities: [(\"Сущность 1\", \"Успешные результаты\"), (\"Сущность 2\", \"распознавания текста\")]\n",
    "        }\n",
    "        Поле сущности так можете дополнять (координаты в текста/на исхображении),\n",
    "        если захотите визуализировать результаты.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c123809",
   "metadata": {
    "id": "0c123809"
   },
   "source": [
    "##### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa1091",
   "metadata": {
    "id": "abfa1091"
   },
   "outputs": [],
   "source": [
    "## Проверка имплементации\n",
    "pipe = Pipeline()\n",
    "model_result = pipe.predict(image)\n",
    "\n",
    "assert all([True if i in {\"recognized_text\", \"entities\"} else False for i in model_result.keys()]), \"Some keys not found in model result\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca4a68",
   "metadata": {
    "id": "85ca4a68"
   },
   "source": [
    "###   Реализация методов сервиса\n",
    "\n",
    "* **version()** - метод **GET**, возвращает версию сервиса\n",
    "* **health()** - метод **GET**, возвращает статус сервиса (Работает / Не работает)\n",
    "* **predict()** - метод **POST**, на вход принмиает запрос - **multipart** - состоящий из файла (изображение для распознавания и извлечения) и дополнительных тезнических параметров\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e10c4e",
   "metadata": {
    "id": "e9e10c4e"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from time import time\n",
    "from flask import Flask, jsonify, make_response, request\n",
    "from service_utils import create_ok_response, create_error_response\n",
    "\n",
    "COMMON_VERSION = \"0.0.1\"\n",
    "DEFAULT_HOST = \"0.0.0.0\"\n",
    "DEFAULT_PORT = 5000\n",
    "\n",
    "\n",
    "def create_app():\n",
    "    \n",
    "    try:\n",
    "        pipe = Pipeline()\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Can not load Pipeline: {e}\")\n",
    "\n",
    "    app = Flask(__name__)\n",
    "\n",
    "    @app.route(\"/version\", methods=[\"GET\"])\n",
    "    def version():\n",
    "        version_data = {\n",
    "            \"common\": COMMON_VERSION\n",
    "        }\n",
    "        return make_response(jsonify({\"version\": version_data}), 200)\n",
    "\n",
    "    @app.route(\"/health\", methods=[\"GET\"])\n",
    "    def health():\n",
    "        output_data = {\n",
    "            \"health_status\": \"running\"\n",
    "        }\n",
    "        return make_response(jsonify(output_data), 200)\n",
    "\n",
    "    @app.route(\"/predict\", methods=[\"POST\"])\n",
    "    def predict():\n",
    "        \n",
    "        received_image = request.files.get(\"image\")\n",
    "        if not received_image:\n",
    "            return make_response(jsonify({\n",
    "                    \"errorMsg\": \"No file with key \\\"image\\\" was found\"\n",
    "                }), 400)\n",
    "        \n",
    "        image_bytes = received_image.read()\n",
    "\n",
    "        \n",
    "        req_params = request.form.get(\"requestParameters\")\n",
    "        if not req_params:\n",
    "            return make_response(jsonify({\n",
    "                    \"errorMsg\": \"Expected key \\\"requestParameters\\\", but not found\"\n",
    "                }), 400)\n",
    "        \n",
    "        input_params = json.loads(req_params)\n",
    "\n",
    "\n",
    "        for param in [\"msgId\", \"workId\", \"msgTm\"]:\n",
    "            if param not in input_params:\n",
    "                return make_response(jsonify({\n",
    "                    \"errorMsg\": f\"Form key requestParameters/\\\"{param}\\\" is not set!\"\n",
    "                }), 400)\n",
    "\n",
    "        try:\n",
    "            \n",
    "            t_start = time()\n",
    "            \n",
    "            image = np.fromstring(image_bytes, np.uint8)\n",
    "            \n",
    "            model_result = pipe.predict(image)\n",
    "\n",
    "        except Exception as e:\n",
    "            output_data = create_error_response(\n",
    "                msg_id=input_params[\"msgId\"],\n",
    "                work_id=input_params[\"workId\"],\n",
    "                error_msg=str(e)\n",
    "            )\n",
    "            return make_response(jsonify(output_data), 500)\n",
    "\n",
    "        t_end = time()\n",
    "\n",
    "        output_data = create_ok_response(\n",
    "            msg_id=input_params[\"msgId\"],\n",
    "            work_id=input_params[\"workId\"],\n",
    "            model_result=model_result,\n",
    "            model_time=t_end - t_start\n",
    "        )\n",
    "\n",
    "        return make_response(json.dumps(output_data, ensure_ascii=False), 200)\n",
    "\n",
    "    return app\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = create_app()\n",
    "    app.run(host=DEFAULT_HOST, port=DEFAULT_PORT, threaded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c6a0c",
   "metadata": {
    "id": "d20c6a0c"
   },
   "source": [
    "Теперь нам нужно запустить наше веб приложение. Для удобства отладки также нужно прописать две базовых переменные среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf598b5",
   "metadata": {
    "id": "3bf598b5"
   },
   "outputs": [],
   "source": [
    "!export FLASK_APP=flask_app.py  # так ак файл с приложение отличается от дефолтного названия app.py (но все в ваших руках)\n",
    "!export FLASK_ENV=development  # чтобы все ошибки писались в лог приложения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db18bb6d",
   "metadata": {
    "id": "db18bb6d"
   },
   "source": [
    "Узнаем версию сервиса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e218d",
   "metadata": {
    "id": "052e218d"
   },
   "outputs": [],
   "source": [
    "!curl http://127.0.0.1:5000/version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff9a88e",
   "metadata": {
    "id": "7ff9a88e"
   },
   "source": [
    "Узнаем статус сервиса: поднят он или нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f2c30",
   "metadata": {
    "id": "f05f2c30"
   },
   "outputs": [],
   "source": [
    "!curl http://127.0.0.1:5000/health"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145eec86",
   "metadata": {
    "id": "145eec86"
   },
   "source": [
    "Отправим реальный запрос с картинкой и параметрам, получим фейковый результат работы сервиса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f297a77",
   "metadata": {
    "id": "5f297a77"
   },
   "outputs": [],
   "source": [
    "!curl -F \"image=@/home/jovyan/SorokinSA/DeepLearning/team_idp/ocr_service/ner_sample/821284f7-4c42-491e-b85d-9d37a2ce7a56.jpeg\" -F  \"requestParameters={\\\"msgId\\\": \\\"string\\\", \\\"msgTm\\\": \\\"2020-04-07T17:52:18.222Z\\\", \\\"workId\\\": \\\"s\\\"}\" http://127.0.0.1:5000/predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da6aba",
   "metadata": {
    "id": "d1da6aba"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "29fc0fe8",
    "61d96d3b",
    "5945b1c2",
    "c57bb05c",
    "b6629973",
    "83d1d2c1",
    "451c9e66",
    "1b58c511",
    "c8e6b6fb",
    "a617dbef",
    "85ca4a68"
   ],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
