{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b3003d88",
      "metadata": {
        "id": "b3003d88"
      },
      "source": [
        "# 0. Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60dd5324",
      "metadata": {
        "id": "60dd5324"
      },
      "source": [
        "На текущий момент мы уже нашли на изображении слова и научились распознавать символы, из которых они состоят. Теперь у нас есть набор слов или кусков предложений, но пока что никак не связанных друг с другом. \n",
        "\n",
        "Для того, чтобы получить связный текст из этих кусков, необходимо связать полученные кусочки друг с другом. Этим мы и займемся в этом ноутбуке.\n",
        "\n",
        "В этом ноутбуке мы будем использовать модель, которая слабо отличается от модели, которая находит слова. Поэтому мы не будем обучать какую-либо новую модель. Вместо этого мы возьмем уже обученную модель, которая умеет находить строки, и будем на основе нее собирать строки.\n",
        "\n",
        "Следующие несколько ячеек будут общими для всех последующих ноутбуков."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Эта ячейка настраивает отображение ipython widgets"
      ],
      "metadata": {
        "id": "sqWUmFLkCuHe"
      },
      "id": "sqWUmFLkCuHe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12638cf1"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
        "%matplotlib inline"
      ],
      "id": "12638cf1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Подключаем Google Drive"
      ],
      "metadata": {
        "id": "BsgqZicPC9WP"
      },
      "id": "BsgqZicPC9WP"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nTZUKkVy2tx_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nTZUKkVy2tx_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_JJiFkCPzkA"
      },
      "source": [
        "* Указываем путь к папке с кодом: "
      ],
      "id": "Q_JJiFkCPzkA"
    },
    {
      "cell_type": "code",
      "source": [
        "repo_folder = '/content/drive/MyDrive/github/'"
      ],
      "metadata": {
        "id": "MvTRdw0utomB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MvTRdw0utomB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Устанавливаем зависимости"
      ],
      "metadata": {
        "id": "vy13l3D3DEhm"
      },
      "id": "vy13l3D3DEhm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AxH5yiBDMYO"
      },
      "outputs": [],
      "source": [
        "reqs_path = repo_folder + 'IntelligentDocumentProcessing/requirements.txt '\n",
        "!pip3 install -r {reqs_path}"
      ],
      "id": "1AxH5yiBDMYO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Подключаем WandB"
      ],
      "metadata": {
        "id": "THY5IHJFDYk-"
      },
      "id": "THY5IHJFDYk-"
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb_key = open('/content/drive/MyDrive/ssh/wandbkey.txt').read()\n",
        "wandb.login(key=wandb_key)"
      ],
      "metadata": {
        "id": "jtsEzC93Da0b"
      },
      "execution_count": null,
      "outputs": [],
      "id": "jtsEzC93Da0b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Подключаем утилиты для этого ноутбука"
      ],
      "metadata": {
        "id": "cJXnmTwXDgft"
      },
      "id": "cJXnmTwXDgft"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "base_folder = repo_folder + 'IntelligentDocumentProcessing/Resources/c_Layout_Analisys/'  # import utils\n",
        "sys.path.append(base_folder)\n",
        "sys.path.append(repo_folder + 'IntelligentDocumentProcessing/Resources/')  # from a_Text_Detection.utils import\n",
        "sys.path.append(repo_folder)  # from IntelligentDocumentProcessing.Resources.a_Text_Detection.utils import"
      ],
      "metadata": {
        "id": "3iq7I9ft4-o_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "3iq7I9ft4-o_"
    },
    {
      "cell_type": "markdown",
      "id": "7656dbb5",
      "metadata": {
        "id": "7656dbb5"
      },
      "source": [
        "# 1. Данные"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38dd1277",
      "metadata": {
        "id": "38dd1277"
      },
      "source": [
        "## 1.1. Аугментации для данных"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f3e8c88",
      "metadata": {
        "id": "8f3e8c88"
      },
      "source": [
        "Для того, чтобы протестировать устойчивость модели к разнообразным изменениям документа, будем использовать аугментации во время тестирования решения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b464e69",
      "metadata": {
        "id": "1b464e69"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Perspective(p=0.7),\n",
        "    A.OpticalDistortion(p=0.7, distort_limit=0.1, shift_limit=0.2, \n",
        "                        border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "    A.ShiftScaleRotate(rotate_limit=10, shift_limit=0, p=0.7, \n",
        "                       border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda33afa",
      "metadata": {
        "id": "fda33afa"
      },
      "source": [
        "## 1.2. Визуальный анализ изображений"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac397404",
      "metadata": {
        "id": "ac397404"
      },
      "source": [
        "Посмотрим, как выглядят тестовые данные (после аугментаций) для этой задачи."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d9fa919",
      "metadata": {
        "id": "4d9fa919"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_dir = '/content/drive/MyDrive/data/la_data/c_Layout_Analisys_data/'\n",
        "image_fpaths = Path(image_dir).glob(\"*.jpg\")\n",
        "\n",
        "for fpath in list(image_fpaths)[:1]:\n",
        "    original_image = cv2.imread(str(fpath))\n",
        "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    image = transform(image=original_image)['image']\n",
        "    h, w, _ = image.shape\n",
        "    # Добавляем по всем краям небольшой паддинг для того, чтобы координаты линий\n",
        "    # не выходили за пределы изображения. Это можно делать более умно и сложно,\n",
        "    # но пока что можно и так:)\n",
        "    pad_transform = A.PadIfNeeded(min_height=h+50, min_width=w+50, border_mode=cv2.BORDER_CONSTANT, value=0)\n",
        "    image = pad_transform(image=image)['image']\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(8,12))\n",
        "    ax1.set_xlabel('Original')\n",
        "    ax2.set_xlabel('Augmented')\n",
        "    ax1.imshow(original_image)\n",
        "    ax2.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "308a318e",
      "metadata": {
        "id": "308a318e"
      },
      "source": [
        "# 2. Пайплайн для скоринга строк"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f63bd13f",
      "metadata": {
        "id": "f63bd13f"
      },
      "source": [
        "## 2.1. Напишем код для детектора строк"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd03125c",
      "metadata": {
        "id": "dd03125c"
      },
      "source": [
        "### Задача 1. Инференс детектора строк"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1e5bee",
      "metadata": {
        "id": "cb1e5bee"
      },
      "source": [
        "\n",
        "\n",
        "Инференс детектора строк совпадает с инференсом детектора текста, но есть одно принципиальное различие: необходимо нормировать все ббоксы по высоте/ширине изображения, чтобы все координаты были в интервале от 0 до 1. Также нужно возвращать список объектов типа `Line`, в которых есть поля `bbox` и `normalized_bbox`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbe0c68b",
      "metadata": {
        "id": "cbe0c68b"
      },
      "source": [
        "#### Код"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38472e42",
      "metadata": {
        "id": "38472e42"
      },
      "outputs": [],
      "source": [
        "from typing import Union, List\n",
        "\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from albumentations import BasicTransform, Compose, OneOf\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from c_Layout_Analisys.utils import Line\n",
        "from a_Text_Detection.utils import DrawMore, Postprocessor\n",
        "\n",
        "# КОД ДЛЯ СТУДЕНТА\n",
        "def line_detector_inference(\n",
        "    model: nn.Module, \n",
        "    image: np.ndarray, \n",
        "    transform: Union[BasicTransform, Compose, OneOf],\n",
        "    postprocessor: Postprocessor,\n",
        "    device: str = 'cpu',\n",
        ") -> List[Line]:\n",
        "    # подготовка изображения (c помощью transform)\n",
        "    ...\n",
        "    # предсказание модели (с помощью model)\n",
        "    ...\n",
        "    # постпроцессинг предсказаний (с помощью postprocessor)\n",
        "    ...\n",
        "    # нормализация bounding box'ов по высоте и ширине\n",
        "    ...\n",
        "    # создание списка объектов типа Line \n",
        "    pass\n",
        "\n",
        "transform = ...\n",
        "postprocessor = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6164b512",
      "metadata": {
        "id": "6164b512"
      },
      "source": [
        "#### Проверка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93c4465",
      "metadata": {
        "id": "a93c4465"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from c_Layout_Analisys.utils import resize_aspect_ratio\n",
        "\n",
        "\n",
        "max_image_size = 2048\n",
        "device='cpu'\n",
        "line_model_path = '/content/drive/MyDrive/data/la_data/la.jit'\n",
        "line_model = torch.jit.load(line_model_path, map_location=device)\n",
        "line_model.eval();\n",
        "\n",
        "image, _, _ = resize_aspect_ratio(image, square_size=max_image_size, interpolation=cv2.INTER_LINEAR)\n",
        "image = image.astype(np.uint8)\n",
        "lines = line_detector_inference(line_model, image, transform, postprocessor, device)\n",
        "\n",
        "assert isinstance(lines, list), 'Метод line_detector_inference должен возвращать список!'\n",
        "assert all(isinstance(line, Line) for line in lines), 'Метод line_detector_inference должен возвращать список объектов типа Line!'\n",
        "for line in lines:\n",
        "    assert isinstance(line.bbox, np.ndarray), 'Каждый bounding box должен быть типа np.ndarray!'\n",
        "    assert isinstance(line.normalized_bbox, np.ndarray), 'Каждый нормализованный bounding box должен быть типа np.ndarray!'\n",
        "    assert line.normalized_bbox.min() >= 0, \"Все элементы нормализованного bounding box'а должны быть больше или равны 0!\"\n",
        "    assert line.normalized_bbox.max() <= 1, \"Все элементы нормализованного bounding box'а должны быть меньше или равны 1!\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7f4c18",
      "metadata": {
        "id": "8c7f4c18"
      },
      "source": [
        "## 2.2. Визуализируем предсказания"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "400265ea",
      "metadata": {
        "id": "400265ea"
      },
      "source": [
        "Посмотрим, какие получются строки у детектора строк:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea8b618",
      "metadata": {
        "id": "5ea8b618"
      },
      "outputs": [],
      "source": [
        "vis_result = image.copy()\n",
        "\n",
        "for line in lines:\n",
        "    DrawMore.draw_contours(vis_result, [line.bbox], thickness=2, inplace=True, color=(0, 0, 255))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(vis_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9efacf9b",
      "metadata": {
        "id": "9efacf9b"
      },
      "source": [
        "# 3. Пайплайн сборки линий в параграфы"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5935af0",
      "metadata": {
        "id": "a5935af0"
      },
      "source": [
        "## 3.1. Каждую строку будем сравнить с другой по трем метрикам:\n",
        "\n",
        "- parallelness - параллельность строк в одном параграфе. Строки параллельны друг другу, если $\\angle(l_1, l_2) \\leq \\theta$\n",
        "- distance - расстояние между двумя строками, в оригинальной статье perpendicular proximity (перпендикулярное расстояние между двумя строками)\n",
        "- overlap - пересечение"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2c05a08",
      "metadata": {
        "id": "c2c05a08"
      },
      "source": [
        "### Задача 2. Реализация методов сравнения строк"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0adadf4",
      "metadata": {
        "id": "c0adadf4"
      },
      "source": [
        "Выше концептуально описаны способы сравнения строк. Вам необходимо реализовать 4 метода (каждый метод работает с нормализованными bounding box): \n",
        "\n",
        "- `_distance` - вертикальное расстрояние между двумя строками. Рассчитывается как евклидово расстояние между $y_{среднее}$ первой строки и $y_{среднее}$ второй строки;\n",
        "- `_length` (необходимо для метода `_overlapping`) - длина линии. В нашем случае это будет евклидово расстояние между двумя первыми точками нормализованного bounding box; \n",
        "- `_overlapping` - рассчитывается следующим образом ($x_{ij}$ - это $x$ координата $j$-й точки $i$-й линии): \n",
        "\n",
        "$$\\frac{min(x_{12}, x_{22}) - max(x_{11}, x_{21})}{length(line_{1})}$$\n",
        "\n",
        "- `_angle` - угол между прямыми, задаваемыми первыми двумя точками каждой строки (можно рассчитать с помощью `math.atan`). Угол обязательно должен быть приведен к величине от -90 до 90 градусов. \n",
        "\n",
        "Все эти методы будут являться частью класса `ParagraphFinder`, частично реализованного ниже. Алгоритм сборки линий в параграфы (метод `find_paragraphs`) будет выглядеть следующим образом: \n",
        "\n",
        "1. Кластеризация входных линий с помощью алгоритма `DBSCAN` с метрикой, основанной на вычислении `_angle`, `_overlapping` и `_distance`;\n",
        "2. Нахождение bounding box для параграфа;\n",
        "3. Сортировка линий внутри параграфа и параграфов внутри страницы."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce04d892",
      "metadata": {
        "id": "ce04d892"
      },
      "source": [
        "#### Код"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "910061dc",
      "metadata": {
        "id": "910061dc"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "from c_Layout_Analisys.utils import sort_boxes_top2down_wrt_left2right_order, sort_boxes, fit_bbox, Paragraph\n",
        "\n",
        "# КОД ДЛЯ СТУДЕНТА\n",
        "class ParagraphFinder:\n",
        "    def __init__(\n",
        "        self, \n",
        "        angle_threshold: int = 10, \n",
        "        overlapping_threshold: float = 0.3, \n",
        "        max_distance: int = 1,\n",
        "        cluster_eps: float = 0.5\n",
        "    ):\n",
        "        self.angle_threshold = angle_threshold\n",
        "        self.overlapping_threshold = overlapping_threshold\n",
        "        self.max_distance = max_distance\n",
        "        self.cluster_eps = cluster_eps\n",
        "    \n",
        "    @staticmethod\n",
        "    def _distance(line1: Line, line2: Line) -> float:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def _length(line: Line) -> float:\n",
        "        pass\n",
        "\n",
        "    def _overlapping(self, line1: Line, line2: Line) -> float:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def _angle(line1: Line, line2: Line) -> float:\n",
        "        pass\n",
        "    \n",
        "    def paragraph_distance(self, line1: np.ndarray, line2: np.ndarray) -> float:\n",
        "        line1 = Line(normalized_bbox=line1.reshape(4, 2))\n",
        "        line2 = Line(normalized_bbox=line2.reshape(4, 2))\n",
        "\n",
        "        if abs(self._angle(line1, line2)) > self.angle_threshold:\n",
        "            return self.max_distance\n",
        "\n",
        "        if self._overlapping(line1, line2) < self.overlapping_threshold:\n",
        "            return self.max_distance\n",
        "\n",
        "        return self._distance(line1, line2)\n",
        "    \n",
        "    @staticmethod\n",
        "    def prepare_lines(lines: List[Line]) -> np.ndarray:\n",
        "        return np.array([line.normalized_bbox.reshape(-1) for line in lines])\n",
        "    \n",
        "    def fit_cluster(self, lines: List[Line]) -> DBSCAN: \n",
        "        prepared_lines = self.prepare_lines(lines)\n",
        "        cluster = DBSCAN(metric=self.paragraph_distance, eps=self.cluster_eps)\n",
        "        cluster.fit(prepared_lines)\n",
        "        return cluster\n",
        "    \n",
        "    @staticmethod\n",
        "    def sort_paragraphs(paragraphs):\n",
        "        for par in paragraphs:\n",
        "            par.items = sort_boxes(par.items, sorting_type = 'top2down')  # сортировка сверху вниз\n",
        "        paragraphs = sort_boxes_top2down_wrt_left2right_order(paragraphs)  # сортировка в порядке чтения\n",
        "        return paragraphs\n",
        "    \n",
        "    def find_paragraphs(self, lines: List[Line]) -> List[Paragraph]:\n",
        "        cluster = self.fit_cluster(lines)\n",
        "        \n",
        "        paragraphs = []\n",
        "        for label in set(cluster.labels_):\n",
        "            line_indexes = np.argwhere(cluster.labels_ == label)\n",
        "            par_lines = [lines[idx[0]] for idx in line_indexes]\n",
        "            bbox = fit_bbox(np.array([lines[idx[0]].bbox for idx in line_indexes]))\n",
        "            par = Paragraph(items=par_lines, bbox=bbox)\n",
        "            paragraphs.append(par)\n",
        "        paragraphs = self.sort_paragraphs(paragraphs)\n",
        "        return paragraphs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c4e70c",
      "metadata": {
        "id": "a8c4e70c"
      },
      "source": [
        "#### Проверка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad94b50",
      "metadata": {
        "id": "fad94b50"
      },
      "outputs": [],
      "source": [
        "paragraph_finder = ParagraphFinder()\n",
        "\n",
        "# возьмем две конкретных линии для проверки\n",
        "norm_bbox_1 = np.array(\n",
        "    [[0.47996795, 0.41517857],\n",
        "     [0.8557692 , 0.43136162],\n",
        "     [0.85336536, 0.45200893],\n",
        "     [0.4775641 , 0.43582588]]\n",
        ")\n",
        "line1 = Line(bbox=np.array([]), normalized_bbox=norm_bbox_1)\n",
        "norm_bbox_2 = np.array(\n",
        "    [[0.48076922, 0.3950893 ],\n",
        "     [0.8733974 , 0.41238838],\n",
        "     [0.8709936 , 0.4330357 ],\n",
        "     [0.4783654 , 0.41573662]]\n",
        ")\n",
        "line2 = Line(bbox=np.array([]), normalized_bbox=norm_bbox_2)\n",
        "\n",
        "# _length\n",
        "assert round(paragraph_finder._length(line1), 4) == 0.3761, 'Что-то не так с методом _length...'\n",
        "assert round(paragraph_finder._length(line2), 4) == 0.393, 'Что-то не так с методом _length...'\n",
        "\n",
        "# _distance\n",
        "assert round(paragraph_finder._distance(line1, line2), 4) == 0.0195, 'Что-то не так с методом _distance...'\n",
        "\n",
        "# _overlapping\n",
        "assert round(paragraph_finder._overlapping(line1, line2), 4) == 0.9969, 'Что-то не так с методом _overlapping...'\n",
        "\n",
        "# _angle\n",
        "assert round(paragraph_finder._angle(line1, line2), 4) == 0.057, 'Что-то не так с методом _angle...'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcc2fae0",
      "metadata": {
        "id": "dcc2fae0"
      },
      "source": [
        "Код готов, для правильной работы осталось только подобрать оптимальные значения параметров. Параметры `angle_threreshold` и `max_distance` мы оставим такими же, как и в конструкторе, а вот `overlapping_threshold` и `cluster_eps` необходимо подобрать. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f0a1cbe",
      "metadata": {
        "id": "6f0a1cbe"
      },
      "source": [
        "### Задача 3.1. Подбор параметра `overlapping_threshold`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ece55a",
      "metadata": {
        "id": "94ece55a"
      },
      "source": [
        "`overlapping_threshold` можно подобрать достаточно просто - взять `lines` с нашего изображения, для всех возможных пар строк посчитать значение функции `paragraph_finder._overlapping` и построить по ним распределение частот. В распределениии будет видно, какое значение хорошо разделит параграфы;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e590ae88",
      "metadata": {
        "id": "e590ae88"
      },
      "source": [
        "#### Код"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c8cbe4",
      "metadata": {
        "id": "a2c8cbe4"
      },
      "outputs": [],
      "source": [
        "# КОД ДЛЯ СТУДЕНТА\n",
        "\n",
        "overlapping_threshold = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c136cd7d",
      "metadata": {
        "id": "c136cd7d"
      },
      "source": [
        "#### Проверка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f1ef78f",
      "metadata": {
        "id": "1f1ef78f"
      },
      "outputs": [],
      "source": [
        "assert 0.1 <= overlapping_threshold <= 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90d767c0",
      "metadata": {
        "id": "90d767c0"
      },
      "source": [
        "### Задача 3.2. Подбор параметра `cluster_eps`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24cc3da5",
      "metadata": {
        "id": "24cc3da5"
      },
      "source": [
        "Данный параметр можно подобрать так называемым elbow method. Для начала необходимо подготовить строки с помощью метода `prepare_lines` из класса `ParagraphFinder`. Затем мы обучаем метод `NearestNeighbors` с параметром `n_neighbors=2`. Зачем мы это делаем? Для того, чтобы найти для каждой строки ближайшего соседа, вычислить до него расстояние и по графику расстояний определить оптимальное значение `cluster_eps` (а это не что иное, как граничное расстояние между двумя элементами кластера). \n",
        "\n",
        "Соответственно, обучив `NearestNeighbors`, необходимо найти для каждой строки соседа и посчитать расстояния от каждой линии до ближайшего соседа. Затем, отсортировав эти расстояния и построив график, вы должны получить примерно следующее: \n",
        "\n",
        "<img src='https://miro.medium.com/max/1014/1*KUYsoRqDm5vVYX9qHB-xeQ.png'>\n",
        "\n",
        "На графике надо найти точку с максимальной кривизной, на картинке выше это примерно значение 0.3 - это и будет искомый параметр `cluster_eps`. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "870fcf02",
      "metadata": {
        "id": "870fcf02"
      },
      "source": [
        "#### Код"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f7fdfe",
      "metadata": {
        "id": "c9f7fdfe"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# КОД ДЛЯ СТУДЕНТА\n",
        "\n",
        "cluster_eps = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "469321e9",
      "metadata": {
        "id": "469321e9"
      },
      "source": [
        "#### Проверка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "691b172d",
      "metadata": {
        "id": "691b172d"
      },
      "outputs": [],
      "source": [
        "assert 0.1 <= cluster_eps <= 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb61313b",
      "metadata": {
        "id": "fb61313b"
      },
      "source": [
        "# 4. Визуализация результата"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c15564",
      "metadata": {
        "id": "80c15564"
      },
      "outputs": [],
      "source": [
        "from c_Layout_Analisys.utils import get_random_color, draw_paragraphs\n",
        "\n",
        "paragraph_finder = ParagraphFinder(overlapping_threshold=overlapping_threshold, cluster_eps=cluster_eps)\n",
        "paragraphs = paragraph_finder.find_paragraphs(lines)\n",
        "draw_paragraphs(image, paragraphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b63a9e1",
      "metadata": {
        "id": "3b63a9e1"
      },
      "source": [
        "Сохраним объект `ParagraphFinder` для использования при сборке приложения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bad6950",
      "metadata": {
        "id": "6bad6950"
      },
      "outputs": [],
      "source": [
        "import dill\n",
        "\n",
        "with open('paragraph_finder.pkl', 'wb') as w:\n",
        "    dill.dump(paragraph_finder, w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c7543e",
      "metadata": {
        "id": "03c7543e"
      },
      "source": [
        "Также предлагаем вам интерактивно изменять параметры `angle_threshold`, `overlapping_threshold` и `cluster_eps` и смотреть, как от этого изменятся параграфы. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a35997f9",
      "metadata": {
        "id": "a35997f9"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact, IntSlider, FloatSlider, fixed\n",
        "\n",
        "def wrapper(image, lines, angle_threshold=10, overlapping_threshold=0.3, cluster_eps=0.5):\n",
        "    paragraph_finder = ParagraphFinder(angle_threshold, overlapping_threshold, 1, cluster_eps)\n",
        "    paragraphs = paragraph_finder.find_paragraphs(lines)\n",
        "    print('Количество параграфов:', len(paragraphs))\n",
        "    draw_paragraphs(image, paragraphs)\n",
        "    \n",
        "interact(\n",
        "    wrapper, \n",
        "    image=fixed(image), \n",
        "    lines=fixed(lines), \n",
        "    angle_threshold=IntSlider(min=0, max=50, step=5, value=10),\n",
        "    overlapping_threshold=FloatSlider(min=0, max=1, step=0.05, value=0.3),\n",
        "    cluster_eps=FloatSlider(min=0.01, max=1.5, step=0.05, value=0.5)\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bbfd72e",
      "metadata": {
        "id": "7bbfd72e"
      },
      "source": [
        "### Задача 4 (опциональная). Визуализация порядка строк"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a9fb3ad",
      "metadata": {
        "id": "4a9fb3ad"
      },
      "source": [
        "Вам необходимо дополнить функцию `draw_paragraphs` (можно найти в файле `IntelligentDocumentProcessing/Resources/3_Layout_Analisys/utils/utils.py`) отрисовкой номеров строк. Для этого можно использовать метод `cv2.putText`. Примерный алгоритм:\n",
        "\n",
        "1. Пишем цикл по всем параграфам;\n",
        "2. В каждом параграфе выбираем цвет и пишем цикл по всем линиям;\n",
        "3. В каждой линии рисуем boudning box этой лини;\n",
        "4. Также в кажжой линии с помощью `cv2.putText` рисуем текст с номером этой линии в этом параграфе (в качестве координат можно выбрать одну из точек линии);\n",
        "5. Отрисовываем изображение с помощью `plt.imshow`. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cc736a7",
      "metadata": {
        "id": "0cc736a7"
      },
      "source": [
        "#### Код"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbfb7eb",
      "metadata": {
        "id": "3fbfb7eb"
      },
      "outputs": [],
      "source": [
        "# КОД ДЛЯ СТУДЕНТА\n",
        "def draw_paragraphs_with_line_idx(image: np.ndarray, paragraphs: List[Paragraph]) -> None:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0759f833",
      "metadata": {
        "id": "0759f833"
      },
      "source": [
        "#### Проверка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf404a3",
      "metadata": {
        "id": "8cf404a3"
      },
      "outputs": [],
      "source": [
        "draw_paragraphs_with_line_idx(image, paragraphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Подведение итогов"
      ],
      "metadata": {
        "id": "cRN26HnF8Oid"
      },
      "id": "cRN26HnF8Oid"
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой тетрадке мы познакомились с одним из методов анализа структуры текста, а подробнее:\n",
        "- Написали инференс модели детекции строк в формате `TorchScript`;\n",
        "- Частично реализовали метод сборки линий в параграфы; \n",
        "- Оптимизировали гиперпараметры алгоритма сборки линий в параграфы;\n",
        "- Визуализировали результаты анализа структуры текста.\n",
        "\n",
        "Основная часть пайплайна, которая связана с обработкой изображений, выполнена. Далее мы плавно переходим из CV в NLP и займемся анализом текстов, распознанных на изображениях. "
      ],
      "metadata": {
        "id": "S4DCFR1o8RR-"
      },
      "id": "S4DCFR1o8RR-"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "enJsvNkN7PTf"
      },
      "id": "enJsvNkN7PTf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}